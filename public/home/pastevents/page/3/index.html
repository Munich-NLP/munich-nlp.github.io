<!DOCTYPE html>
<html lang="en">
  <head>
  	<meta charset="utf-8">
  	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
  	<meta name="description" content="">
  	<meta name="author"      content="map[]">
    
    	<title>Past Events</title>
	<link rel="shortcut icon" href="https://munich-nlp.github.io/images/favicon.png">

	
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	
	
	<script defer src="https://use.fontawesome.com/releases/v5.0.11/js/all.js" integrity="sha384-ImVoB8Er8knetgQakxuBS4G3RSkyD8IZVVQCAnmRJrDwqJFYUE4YOv+DbIofcO9C" crossorigin="anonymous"></script>
	
	
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	
	
  
  <link rel="stylesheet" href="https://munich-nlp.github.io/css/styles.min.ee9878fb7975c98855fa270ff7cfab08fc1644cf609d7aa8cb8338f5cba9dd1f2fafaf1e708aab938e9e61081d30e63175872b714e7a4dee0c40f128687f4075.css" integrity="sha512-7ph4&#43;3l1yYhV&#43;icP98&#43;rCPwWRM9gnXqoy4M49cup3R8vr68ecIqrk46eYQgdMOYxdYcrcU56Te4MQPEoaH9AdQ==">

   
  

    <style>
       

      @import url('https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@300&display=swap');
    </style>
  </head>
  
  <body class="home">

    
      <header id="header">
  <div id="head" class="parallax" data-parallax-speed="2" style="background-image:url('https://munich-nlp.github.io/');">
    <h1 id="logo" class="text-center">
      <img class='img-noborder' src="https://munich-nlp.github.io/images/munichnlp.png" alt="">
      
      <span class="tagline"><br>
        <a href="mailto:"></a>
      </span>
   </h1>
</div>

<nav class="navbar navbar-default">
    <div class="container-fluid">

        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="true">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>

        <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1">

            <ul class="nav navbar-nav">
            
                
                <li>
                    <a href="/#about">About</a>
                </li>
                
            
                
                <li>
                    <a href="/#upcomingevents">Upcoming events</a>
                </li>
                
            
                
                <li>
                    <a href="/#pastevents">Past events</a>
                </li>
                
            
                
                <li>
                    <a href="/#partners">Partners</a>
                </li>
                
            
                
                <li>
                    <a href="/#organizers">Organizers</a>
                </li>
                
            
            </ul>

        </div> 
        
    </div>
</nav>

</header>
    
 
    
<main id="main">

	<div class="container">
		<div class="row topspace">
			<div class="col-sm-8 col-sm-offset-2">

        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">November 10, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/tricks-and-tools-from-nlp-land/" rel="bookmark">Tricks and Tools from NLP Land</a>
						</h1>
					</header>
					<div class="entry-content">
						<!-- raw HTML omitted -->

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/sjiASMMbHao" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>What if we did not use transformers? Can we still do NLP? Yes.</p>
<p>In this talk, Vincent will discuss some effective tricks in NLP that don&rsquo;t require a transformer or a GPU. It will be a collection of techniques that he has seen work in the field including some tricks with embeddings, annotation techniques, tf-idf, subword embeddings, and multi-word embeddings. Many of these techniques can also be used outside of the realm of NLP and most of the topics will be discussed via a live demo.</p>
<p>If there is time, Vincent might also show a very cool fine-tuning trick!</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/vincent-warmerdam.jpg" alt="Vincent Warmerdam &gt;&lt;"></p>
<p><strong>Vincent Warmerdam</strong> worked as an engineer, consultant, researcher, team lead, and educator in the past. He currently works as a Machine Learning Engineer at Explosion. He also maintains many small open source packages, including many scikit-learn related plugins. He blogs over at koaning.io and he also maintains an increasingly popular free learning resource over at calmcode.io</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">October 26, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/nlp-for-social-good-survey/" rel="bookmark">NLP for Social Good: A Survey with Use-Cases</a>
						</h1>
					</header>
					<div class="entry-content">
						<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/B-LBo-w4CrA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>Today, a large spectrum of NLP models have been developed covering various fields ranging from already-usual-for-everyday web search, to helpers for programmers to write code. However, quite a few of the modern NLP technologies were explored in terms of their application for social good.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/ev_nlp_nlp4socg_daryna_dem/daryna-dementieva.png" alt="Daryna Dementieva &gt;&lt;"></p>
<p><strong>Daryna Dementieva</strong> is a post-doc researcher at Social Research Computing Lab in TUM. Previously, she finished her PhD in Skoltech University under the supervision of Prof. Alexander Panchenko with the topic &ldquo;Methods for Fighting Harmful Multilingual Textual Content&rdquo;. In general, Daryna&rsquo;s research is connected with different applications of NLP for Social Good. During her PhD, she worked with topics of fake news detection and text detoxification. Moreover, she participated in several competitions and hackathons wrapping obtained raw NLP models into product demonstrations. Daryna would like to inspire with her studies research and development of NLP-based products for real-life applications with positive impact.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">October 13, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/simplifying-mlops-stack/" rel="bookmark">Simplifying MLOps Stack</a>
						</h1>
					</header>
					<div class="entry-content">
						<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/vdDdX-xf_mM" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>Running ML workflows involves a lot of hurdles, especially if you donâ€™t have a FAANG-level ML infrastructure. Classical MLOps platforms provide a certain level of automation but often require a complex setup and may stand in the way more than help. Particularly, if you want to run modular code (rather than spread it over a notebook), use Git, and your favourite code editor and terminal. Join this meet-up to learn more about the tool, and general best practices related to setting up your dev environment for ML.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/andrey-cheptsov.jpeg" alt="Andrey Cheptsov &gt;&lt;"></p>
<p><strong>Andrey Cheptsov</strong> is the creator of dstack, a very lightweight open-source utility that allows to provision ML infra via command-line. He is passionate about open-source and developer tools for AI. Previously, Andrey worked at JetBrains with the PyCharm team.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">October 13, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/transformers-in-all-glory-details/" rel="bookmark">Transformers in All Glory Details</a>
						</h1>
					</header>
					<div class="entry-content">
						<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/dqb4U-QzMbs" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>In this talk, Lucas will take a deep dive into the Transformer architecture and the attention mechanism. He will provide context around the model, and explain how it has recently been adapted to various ML communities/modalities. The slides are available at <a href="http://lucasb.eyer.be/transformer">http://lucasb.eyer.be/transformer</a></p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/lucas-beyer.jpeg" alt="Lucas Beyer &gt;&lt;"></p>
<p><strong>Lucas Beyer</strong> grew up in Belgium wanting to make video games and their AI, went on to study mechanical engineering at RWTH Aachen in Germany, did a PhD in robotic perception/computer vision there too, and is now researching representation learning and vision backbones at Google Brain in ZÃ¼rich.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">September 22, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/next-generation-of-semantic-search/" rel="bookmark">Next Generation of Semantic Search</a>
						</h1>
					</header>
					<div class="entry-content">
						<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/Y0g_ENURKFk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>Using deep neural networks to map text to dense vector spaces (also known as semantic search), has brought tremendous progress to textual information retrieval. However, recent research showed that this widely adopted approach is extremely sensitive to data drift and performs poorly on out-of-domain and long tail queries.</p>
<p>In this talk, Nils will give an introduction to the next generation of semantic search architectures. First, he will talk about hybrid continuous-binary approaches that can lead up to a 100 times cost reduction for deploying semantic search. Then, he will present learned sparse representations that perform a lot better in terms of data drift, out-of-domain and long tail queries. These approaches are especially suited in domains with quickly evolving information needs like news retrieval.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/nils-reimers.jpeg" alt="Nils Reimers &gt;&lt;"></p>
<p><strong>Nils Reimers</strong> is an expert on search relevance using pre-trained transformer networks. In 2018, he authored and open-sourced the popular sentence-transformers.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">July 6, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/language-models-for-symbolic-music-generation/" rel="bookmark">Language Models for Symbolic Music Generation</a>
						</h1>
					</header>
					<div class="entry-content">
						<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/LZQIQxogFEk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>Tristan Behrens will present how Language Models can be used to compose music, thus effectively bridging the GAP between NLP and symbolic music generation, and further talk about his experience in the field.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/tristan-behrens.jpeg" alt="Tristan Behrens &gt;&lt;"></p>
<p><strong>Tristan Behrens</strong> is an expert in AI, an AI composer, and an AI educator. He has an extensive track record in successful Deep Learning projects. His biggest focus is Deep Neural Networks for composition. He has published several albums of music composed with the computer.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">June 29, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/accelerating-transformers-in-production/" rel="bookmark">Accelerating Transformers in Production</a>
						</h1>
					</header>
					<div class="entry-content">
						<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/CAbHbm9769Q" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>Lewis Tunstall will talk about optimization of transformer models. He will cover knowledge distillation and weight quantization as well as frameworks like ONNX Runtime and Hugging Face Optimum.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/lewis-tunstall.jpeg" alt="Lewis Tunstall &gt;&lt;"></p>
<p><strong>Lewis Tunstall</strong> is a Machine Learning Engineer at Hugging Face. He is responsible for implementing the tooling to conduct large-scale evaluations of the 10,000+ models and 1,000+ datasets hosted on the Hugging Face Hub. Recently, he published a book called &ldquo;Natural Language Processing with Transformers&rdquo;.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">June 23, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/hands-on-tutorial-huggingface-gradio/" rel="bookmark">A Hands-on Tutorial of the Hugging Face Hub and Gradio</a>
						</h1>
					</header>
					<div class="entry-content">
						<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/EazTFBSpdns" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="about-this-event">About this event</h3>
<p>Abubakar Abid will hold an online tutorial covering practical tools for modern Machine Learning, ML datasets, models, and demos. He will present how to use the HuggingFace Hub, an online playground for ML models, quickly find suitable models and datasets for your ML tasks, and how to make them work using Gradio.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/abubakar-abid.jpeg" alt="Abubakar Abid &gt;&lt;"></p>
<p><strong>Abubakar Abid</strong> is the founder of <a href="https://www.gradio.dev">Gradio</a> and currently ML Team Lead at HuggingFace. He holds a PhD from Stanford University, in which his research focus was building reliable deep learning models with applications to biology and medicine.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">June 18, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/pretrained-language-models-evaluating-themselves/" rel="bookmark">Pre-trained language models evaluating themselves - A comparative study</a>
						</h1>
					</header>
					<div class="entry-content">
						<h3 id="about-this-event">About this event</h3>
<p>We will take a dive into the field of evaluation of generated text where Philipp Koch will present his paper &ldquo;Pre-trained language models evaluating themselves - A comparative study&rdquo; (<a href="https://aclanthology.org/2022.insights-1.25/)">https://aclanthology.org/2022.insights-1.25/)</a>, which was recently accepted to the Workshop on Insights from Negative Results in NLP @ACL'22.</p>
<p>Evaluation of generated text remains a significant issue. Recently introduced model-based metrics have shown promising results compared to n-gram-based metrics like BLEU, yet they still suffer severe drawbacks.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/ev_nlp_langmod_eval_phil_koch/philipp-koch.jpg" alt="Philipp Koch &gt;&lt;"></p>
<p><strong>Philipp Koch</strong> is one of the founders of Munich NLP. He is currently studying M.Sc. Statistics and Data Science at LMU.</p>
					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="">May 27, 2022</time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://munich-nlp.github.io/events/life-after-bert/" rel="bookmark">Life after BERT: What do Other Muppets Understand about Language?</a>
						</h1>
					</header>
					<div class="entry-content">
						<h3 id="about-this-event">About this event</h3>
<p>How does model architecture, pre-training objective, the side of the dataset and parameter count affect model&rsquo;s linguistic abilities? They don&rsquo;t ðŸ¤¯. Or at least not as directly we thought.
Evaluation of generated text remains a significant issue. Recently-introduced model-based metrics have shown promising results compared to n-gram-based metrics like BLEU, yet they still suffer severe drawbacks (<a href="http://arxiv.org/abs/2205.10696)">http://arxiv.org/abs/2205.10696)</a>.</p>
<h3 id="speaker">Speaker</h3>
<p><img src="/images/vlad.jpeg" alt="Vladislav Lialin &gt;&lt;"></p>
<p><strong>Vladislav Lialin</strong> is a computer science PhD student at University of Massachusetts Lowell advised by Anna Rumshisky. His research areas include continual learning for large language models, multimodal learning, and model analysis. In particular, he is hyping large-scale models and thinks that every task is a language modeling task if you try hard enough. He is currently interning at Amazon Alexa AI.</p>
					</div>
				</article>
        
			</div>
		</div>

		<center class="">
			<ul class="pagination">
        
    <ul class="pagination pagination-default">
      <li class="page-item">
        <a href="/home/pastevents/" aria-label="First" class="page-link" role="button"><span aria-hidden="true">&laquo;&laquo;</span></a>
      </li>
      <li class="page-item">
        <a href="/home/pastevents/page/2/" aria-label="Previous" class="page-link" role="button"><span aria-hidden="true">&laquo;</span></a>
      </li>
      <li class="page-item">
        <a href="/home/pastevents/" aria-label="Page 1" class="page-link" role="button">1</a>
      </li>
      <li class="page-item">
        <a href="/home/pastevents/page/2/" aria-label="Page 2" class="page-link" role="button">2</a>
      </li>
      <li class="page-item active">
        <a aria-current="page" aria-label="Page 3" class="page-link" role="button">3</a>
      </li>
      <li class="page-item disabled">
        <a aria-disabled="true" aria-label="Next" class="page-link" role="button" tabindex="-1"><span aria-hidden="true">&raquo;</span></a>
      </li>
      <li class="page-item disabled">
        <a aria-disabled="true" aria-label="Last" class="page-link" role="button" tabindex="-1"><span aria-hidden="true">&raquo;&raquo;</span></a>
      </li>
    </ul>
			</ul>
		</center>
	</div>	

</main>

    
    
      <footer id="footer">
	<div class="container">
		<div class="row">
			

			
			<div class="col-md-3 widget">
				<h3 class="widget-title">Follow us!</h3>
				<div class="widget-body">
					<p class="follow-me-icons">
            
							
								<a href="https://discord.com/invite/BgFaZgZ38N" target="_blank"><i class="fab fa-discord fa-1x"></i></a>
							
            
							
								<a href="https://www.youtube.com/channel/UCmpRQbcw7dOiXSyWpGYwk3Q" target="_blank"><i class="fab fa-youtube fa-1x"></i></a>
							
            
							
								<a href="https://twitter.com/munichnlp" target="_blank"><i class="fab fa-twitter-square fa-1x"></i></a>
							
            
							
								<a href="https://www.linkedin.com/company/munich-nlp/" target="_blank"><i class="fab fa-linkedin fa-1x"></i></a>
							
            
							
								<a href="https://github.com/Munich-NLP" target="_blank"><i class="fab fa-github fa-1x"></i></a>
							
            
							
								<a href="mailto:munichnlp@gmail.com" target="_blank"><i class="fas fa-envelope-square fa-1x"></i></a>
							
            
					</p>
				</div>
			</div>
			

			

			

		</div> 
	</div>
</footer>






<script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>




<script src="https://munich-nlp.github.io/js/bundle.min.8adc00f11fb328590a42ed3b14d3ec5b116abb98395a8a662d782f2150a7de6cc85eacb26c14724bb0c5130a11be2933c9b4f835cd3a053e90f036e210fbdd5d.js" integrity="sha512-itwA8R&#43;zKFkKQu07FNPsWxFqu5g5WopmLXgvIVCn3mzIXqyybBRyS7DFEwoRvikzybT4Nc06BT6Q8DbiEPvdXQ=="></script>

<script id="dsq-count-scr" src="//hugo-initio-site.disqus.com/count.js" async></script>
<script>
  
  
  
  

  
  
</script>

</body>
</html>

    
  </body>
  
</html>