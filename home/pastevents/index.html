<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content="map[]"><title>Past Events</title><link rel="shortcut icon" href=https://munich-nlp.github.io/images/favicon.png><link href=https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css rel=stylesheet><script defer src=https://use.fontawesome.com/releases/v5.0.11/js/all.js integrity=sha384-ImVoB8Er8knetgQakxuBS4G3RSkyD8IZVVQCAnmRJrDwqJFYUE4YOv+DbIofcO9C crossorigin=anonymous></script>
<link rel=stylesheet href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700"><link rel=stylesheet href=https://munich-nlp.github.io/css/styles.min.ee9878fb7975c98855fa270ff7cfab08fc1644cf609d7aa8cb8338f5cba9dd1f2fafaf1e708aab938e9e61081d30e63175872b714e7a4dee0c40f128687f4075.css integrity="sha512-7ph4+3l1yYhV+icP98+rCPwWRM9gnXqoy4M49cup3R8vr68ecIqrk46eYQgdMOYxdYcrcU56Te4MQPEoaH9AdQ=="><style>@import 'https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@300&display=swap'</style></head><body class=home><header id=header><div id=head class=parallax data-parallax-speed=2 style=background-image:url(https://munich-nlp.github.io/)><h1 id=logo class=text-center><img class=img-noborder src=https://munich-nlp.github.io/images/munichnlp.png alt>
<span class=tagline><br><a href=mailto:></a></span></h1></div><nav class="navbar navbar-default"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#bs-example-navbar-collapse-1 aria-expanded=true>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="navbar-collapse collapse" id=bs-example-navbar-collapse-1><ul class="nav navbar-nav"><li><a href=/#about>About</a></li><li><a href=/#upcomingevents>Upcoming events</a></li><li><a href=/#pastevents>Past events</a></li><li><a href=/#partners>Partners</a></li><li><a href=/#organizers>Organizers</a></li></ul></div></div></nav></header><main id=main><div class=container><div class="row topspace"><div class="col-sm-8 col-sm-offset-2"><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>October 20, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/tumai-summit/ rel=bookmark>AI Summit Munich 2023</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src="https://www.youtube.com/embed/Ug5c92gxDu0?si=N0ynH37F3Aza0Gn3" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this event</h3><p>How does model architecture, pre-training objective, the side of the dataset and parameter count affect model&rsquo;s linguistic abilities? They don&rsquo;t ðŸ¤¯. Or at least not as directly we thought.
Evaluation of generated text remains a significant issue. Recently-introduced model-based metrics have shown promising results compared to n-gram-based metrics like BLEU, yet they still suffer severe drawbacks (<a href=http://arxiv.org/abs/2205.10696)>http://arxiv.org/abs/2205.10696)</a>.</p><h3 id=slides>Slides</h3><div id=Container style=padding-bottom:56.25%;position:relative;display:block;width:100%><iframe id=googleSlideIframe width=100% height=100% src="https://docs.google.com/presentation/d/e/2PACX-1vT6GIGbxgpFRmfjxrCXq2hAmbnHXVbxuwGChjR2Dd76WaLQId-TeRVE299fsizMBkw4vIorvy74P4pI/embed?start=false&amp;loop=false&amp;delayms=3000" frameborder=0 allowfullscreen style=position:absolute;top:0;left:0></iframe></div><h3 id=speaker>Speaker</h3><p><img src=/images/muhtasham-oblokulov.jpg alt="Muhtasham Oblokulov ><"></p><p><strong>Muhtasham Oblokulov</strong> is a Machine Learning Engineer at Munich Re. He is passionate about applied AI, specifically transfer learning in NLP. Apart from that, his experience lies in Brain Computer Interfaces, Anomaly and Out of Distribution detection, Synthetic Data Augmentation, and NLP for Low-Resource Languages. In May 2022, he co-founded Munich NLP with colleagues from TUM and LMU.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>October 4, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/pydata-x-mucnlp-october-23/ rel=bookmark>MunichNLP x PyData October Meetup</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/RrRAPuW9pPQ style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/mbiJlORaZvU style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p>Hallo MÃ¼nchners,</p><p>We would like to invite you to our October meetup with two exciting talks at a very cool location, for which we want to thank Alasco for hosting us this evening & sponsoring the refreshments.</p><p>This event is brought to you in collaboration with the MunichNLP community. Join their Discord to discuss the latest developments and also stimulate exchange on research and innovation around NLP.
Hurry up we have limited spots and see you on the other side.</p><h3 id=agenda>Agenda</h3><ul><li>6:30pm Door opening, pizza arrives, drinks, casual welcoming</li><li>7:00pm Quick Introduction - 3min (MunichNLP) + 2 mins welcome words from Alasco</li><li>7:05pm Lanfrica: Tackling the deep-rooted AI challenges in the Global majority + Q&amp;A by Chris Emezue</li><li>7:50 pm Break</li><li>8:00pm Approaches to Question Answering in Network Engineering + Q&amp;A by Dr. Oliver Pfaffel</li><li>8:30pm Break</li><li>9:00pm Food and Drinks + Networking</li><li>9:55pm Event conclusion</li></ul><h3 id=speaker>Speaker</h3><p><img src="https://media.licdn.com/dms/image/C5603AQEBCaYpwagcWQ/profile-displayphoto-shrink_200_200/0/1588976757668?e=1700697600&amp;v=beta&amp;t=SOWkuwHDxhrKPJZB_4tMEy6zR3_Cwgv2e10UoZwaG2Y" alt="Chris Emezue ><"></p><p><a href=https://www.linkedin.com/in/chrisemezue/><strong>Chris Emezue</strong></a> is a seasoned researcher committed to developing intelligent systems that can learn even in low-resource scenarios, and are reliable. His research areas are natural language processing, causality, and reinforcement learning. As a dedicated contributor to the field of AfricaNLP, he has worked on several key projects to improve the representation of low-resource African language technologies and datasets. Furthermore, as an entrepreneur, Chris is building Lanfrica, a startup that aims to accelerate the development of AI applications in under-represented regions.</p><p><img src=/images/oliver-pfaffel.jpg alt="Oliver Pfaffel ><"></p><p><a href=https://www.linkedin.com/in/oliver-pfaffel/><strong>Dr. Oliver Pfaffel</strong></a> has been working as a data scientist / NLP engineer in insurance for more than a decade. He holds a PhD in mathematical statistics (TUM, Columbia, NUS) and regularly lectures at the European Actuarial Academy and TUM. In this introductory talk, we delve into various strategies employed for question answering tailored specifically to the field of network engineering. We will cover generative solutions using large language models as well as retrieval-based techniques, which we will demonstrate using a sample StackExchange dataset. Considerations will be given to the use of private or confidential data. We will critically analyze different evaluation types, elaborating on their respective advantages and limitations. It is important to note that this presentation is grounded in a personal project and holds no affiliation to any professional activity or company.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>September 27, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/dora-exploring-outlier-representations/ rel=bookmark>Online Event | DORA: Exploring Outlier Representations in Deep Neural Networks</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/EXNsx5k-hI4 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p>Deep Neural Networks (DNNs) draw their power from the representations they learn. In recent years, however, researchers have found that DNNs, while being incredibly effective in learning complex abstractions, also tend to be infected with artifacts, such as biases, Clever Hanses (CH), or Backdoors, due to spurious correlations inherent in the training data. So far, existing methods for uncovering such artifactual and malicious behavior in trained models focus on finding artifacts in the input data, which requires both availabilities of a data set and human intervention. In this paper, we introduce DORA (Data-agnOstic Representation Analysis): the first automatic data-agnostic method for the detection of potentially infected representations in Deep Neural Networks. We further show that contaminated representations found by DORA can be used to detect infected samples in any given dataset. We qualitatively and quantitatively evaluate the performance of our proposed method in both, controlled toy scenarios, and in real-world settings, where we demonstrate the benefit of DORA in safety-critical applications.</p><h3 id=speaker>Speaker</h3><p><img src=https://www.atb-potsdam.de/fileadmin/_processed_/4/5/csm_1900-64a3cf253181d_075d9305f4.png alt="Kirill Bykov ><"></p><p><a href=https://www.atb-potsdam.de/de/ueber-uns/team/mitarbeiter/person/kirill-bykov><strong>Kirill Bykov</strong></a> is a doctoral student in Machine Learning at the Technische UniversitÃ¤t Berlin and ATB, with a focus on Interpretable and Explainable AI. When asked about his work, He likes to answer that he investigates the vivid diversity of the internal abstractions and representations learned by machines to understand how they perceive the world.</p><p>Apart from academia, He is also am a passionate photographer (only if he had more time to do that), an ardent reader and I am aroused by writing.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>June 15, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/GenerataX/ rel=bookmark>GenerataX MiniConference</a></h1></header><div class=entry-content><script>location.replace("https://www.generatax.com/")</script></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>May 25, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/reality-check-nlp-in-the-era-of-llms/ rel=bookmark>Reality Check: Natural Language Processing in the era of Large Language Models</a></h1></header><div class=entry-content><h3 id=about-this-event>About this Event</h3><p>Large language models (LLMs) contributed to a major breakthrough in NLP, both in terms of understanding natural language queries, commands or questions; and in generating relevant, coherent, grammatical, human-like text. LLMs like ChatGPT became a product used by many, for getting advice, writing essays, troubleshooting and writing code, creative writing, and more. This calls for a reality check: which NLP tasks did LLMs solve? What are the remaining challenges, and which new opportunities did LLMs create?</p><p>In this talk, I will discuss several areas of NLP that can benefit from but are still challenging for LLMs: grounding, i.e. interpreting language based on non-linguistic context; reasoning; and real-world applications. Finally, I will argue that the standard benchmarking and evaluation techniques used in NLP need to drastically change in order to provide a more realistic picture of current capabilities.</p><h3 id=speaker>Speaker</h3><p><img src=https://www.cs.ubc.ca/~vshwartz/images/vered-shwartz.jpg alt="Vered Shwartz ><"></p><p><a href=https://www.cs.ubc.ca/~vshwartz/><strong>Vered Shwartz</strong></a> is an Assistant Professor of Computer Science at the University of British Columbia, and a CIFAR AI Chair at the Vector Institute. Her research interests include commonsense reasoning, computational semantics and pragmatics, and multiword expressions. Previously, Vered was a postdoctoral researcher at the Allen Institute for AI (AI2) and the University of Washington, and received her PhD in Computer Science from Bar-Ilan University. Vered&rsquo;s work has been recognized with several awards, including The Eric and Wendy Schmidt Postdoctoral Award for Women in Mathematical and Computing Sciences, the Clore Foundation Scholarship, and an ACL 2016 outstanding paper award.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>May 16, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/pydata-nights/ rel=bookmark>PyData Nights talks from JinaAI and LMU</a></h1></header><div class=entry-content><p><img src=/images/ev_pydata_nights/theme_photo.png alt="PyData Nights talks from JinaAI and LMU ><"></p><h3 id=location>Location</h3><p><a href="https://www.google.com/maps/search/?api=1&amp;query=48.145863%2C%2011.505231">JetBrains Event Space Christoph-Rapparini-Bogen 23 Â· MÃ¼nchen, BY</a>.</p><h3 id=about-this-event>About this Event</h3><h4 id=cutting-through-the-hype-jina-ais-scalable-open-source-solutions-for-multimodal-ai>Cutting Through the Hype: Jina AI&rsquo;s Scalable Open-Source Solutions for Multimodal AI</h4><p>In this talk, we will showcase how Jina AI helps organizations cut through the AI hype by providing practical and scalable AI solutions for industrial domains where stability, availability, and business value are crucial. You will learn how our open-source MLOps framework and multimodal products empower a seamless transition from research to industry-level applications across various sectors.</p><h4 id=longform-improve-instruction-tuning-with-corpus-examples-and-generated-instructions>LongForm: Improve instruction tuning with corpus examples and generated instructions.</h4><p>Instruction tuning enables language models to generalize more effectively and better follow user intent. However, obtaining instruction data can be costly and challenging. Prior works employ methods such as expensive human annotation, crowd-sourced datasets with alignment issues, or generating noisy examples via LLMs. We introduce the LongForm dataset, which is created by leveraging English corpus examples with augmented instructions. We select a diverse set of human-written documents from existing corpora such as C4 and Wikipedia and generate instructions for the given documents via LLMs. This approach provides a cheaper and cleaner instruction-tuning dataset and one suitable for long text generation. We finetune T5, OPT, and LLaMA models on our dataset and show that even smaller LongForm models have good generalization capabilities for text generation. Our models outperform 10x larger language models without instruction tuning on various tasks such as story/recipe generation and long-form question answering. Moreover, LongForm models outperform prior instruction-tuned models such as FLAN-T5 and Alpaca by a large margin. Finally, our models can effectively follow and answer multilingual instructions; we demonstrate this for news generation.</p><h3 id=speakers>Speakers</h3><p><img src=https://pbs.twimg.com/profile_images/1640989888005767170/RucvgIKR_400x400.jpg alt="Saahil Ognawala ><"></p><p><a href=http://www.saahilognawala.com/><strong>Saahil Ognawala</strong></a> is Senior Product Manager at Jina AI, a cutting edge Multimodal AI startup founded in 2020 which has already appeared in Forbes AI30 and CBInsights AI100. Saahil has previously worked as a data scientist and product manager for Munich Re. Prior to that, he finished his M.Sc. and PhD Computer Science at the Technical University of Munich, specializing in deep learning and software engineering.</p><p><img src=https://akoksal.com/images/profile_custom.jpeg alt="Abdullatif KÃ¶ksal ><"></p><p><a href=https://akoksal.com/><strong>Abdullatif KÃ¶ksal</strong></a> is a second-year ELLIS PhD Student at Ludwig Maximilian University of Munich and Cambridge University, co-advised by Hinrich SchÃ¼tze and Anna Korhonen. His research lies in the fields of unsupervised and few-shot learning and their applications on both large and small language models, such as instruction tuning and prompt-based finetuning. In addition to this, he has conducted research in the areas of bias in PLMs, computational social science, and text generation. Previously, Abdullatif worked as an applied science intern at Amazon Books in Madrid, focusing on structured prediction from long-text documents. He completed a BSc and MSc at Bogazici University, advised by Arzucan Ozgur.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>May 11, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/special-anniversary/ rel=bookmark>Special Anniversary Edition: Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning</a></h1></header><div class=entry-content><p><img src=/images/ev_special_anniversary/theme_photo.png alt="Special Anniversary Edition: Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning ><"></p><h3 id=about-this-event>About this Event</h3><p>This paper presents a systematic overview and comparison of parameter-efficient fine-tuning methods covering over 40 papers published between February 2019 and February 2023. These methods aim to resolve the infeasibility and impracticality of fine-tuning large language models by only training a small set of parameters. We provide a taxonomy that covers a broad range of methods and present a detailed method comparison with a specific focus on real-life efficiency and fine-tuning multibillion-scale language models.</p><h3 id=speaker>Speaker</h3><p><img src=https://vladlialin.com/images/avatar.jpg alt="Vladislav Lialin ><"></p><p><a href=https://vladlialin.com/><strong>Vladislav Lialin</strong></a> is a computer science PhD student at University of Massachusetts Lowell advised by Anna Rumshisky. His research areas include continual learning for large language models, multimodal learning, and model analysis. In particular, he is hyping large-scale models and thinks that every task is a language modeling task if you try hard enough. He is currently interning at Amazon Alexa AI.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>April 20, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/measuring-political-positions-using-contextual-word-embeddings/ rel=bookmark>Measuring political positions using contextual word embeddings</a></h1></header><div class=entry-content><p><img src=/images/ev_pol_nlp/theme_photo.png alt="Measuring political positions using contextual word embeddings ><"></p><h3 id=about-this-event>About this Event</h3><p>I will talk about how in the social sciences (primarily political and communication science), neural NLP is being used
to measure constructs of interest that have previously been measured by hand coding.
I illustrate this with results from experiments on parliament speeches and party manifestos from the
last legislative period in Germany (2017-2021). One key issue I want to discuss (and where social science and computer science sometimes have a different understanding) is measurement validity.</p><p><img src=https://www.ls1.ifkw.uni-muenchen.de/bilder/web_bilder_m/patrick.JPG alt="Patrick Schwabl ><"></p><p><a href=https://patschw.github.io><strong>Patrick Schwabl</strong></a> is a Ph.D. student at LMU Munich. He works at the chair for Computational Communication Research of Professor Mario Haim. His research uses word embeddings to measure social science constructs like political positions or societal cleavages in textual data.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>April 20, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/women-get-together-in-nlp/ rel=bookmark>Women Get-Together in NLP</a></h1></header><div class=entry-content><p><img src=/images/ev_women_in_nlp/theme_photo.jpg alt="Women Get-Together in NLP ><"></p><h2 id=highlights-of-the-event>Highlights of the Event</h2><p>Our get-together event on was a huge success, with female leaders sharing their experiences; and attendees engaging in thought-provoking conversations and making valuable new connections. Here are some of the highlights of this memorable evening:
<img src=/images/ev_women_in_nlp/get_together.png alt="Get-Together in NLP"></p><h2 id=original-post>Original Post</h2><h3 id=about-this-event>About this Event</h3><p>We are excited to announce that We&rsquo;re organising a get-together event for women in nlp.
Our goal is to create a supportive and inclusive environment where young female students can share their experiences, seek valuable career advice, and network with female leaders.</p><p>During the event, you can expect:</p><ul><li><p>ðŸŽ¤ Inspiring panel talks from female leaders. Barbara Plank from Ludwig-Maximilians-UniversitÃ¤t MÃ¼nchen, Annette Green from Microsoft and Claudia Schulze from Convalid Analytics GmbH will share their experiences in NLP and Data Science.</p></li><li><p>ðŸ’¬ &ldquo;Round Tables&rdquo; discussion groups where you can connect with mentors, and receive guidance and self-empowerment tips.</p></li><li><p>ðŸ¥‚ Networking opportunities with drinks and snacks provided.</p></li></ul><p>Join us on April 24th at 18:30 at ThierschstraÃŸe 20 in Munich for an opportunity to connect with like-minded women in this exciting field. Don&rsquo;t miss out on this chance to network and grow in NLP.</p><p>I would also like to express sincere gratitude to <a href=https://convalid-ai.de/>Convalid Analytics GmbH Analytics</a> for generously sponsoring the venue and food for the event, and for providing a valuable platform for the female NLP community to connect and grow together.</p><p>Please RSVP via <a href=https://lnkd.in/ewV_vXvA>this link</a> ðŸ”— and feel free to share with your networks.</p><h3 id=agenda>Agenda</h3><ul><li>6:30 pm Informal Get Together</li><li>7:00 pm Welcome and Introduction of the Event Mentors</li><li>7:15 pm <strong>Expereince Sharing Panels</strong> /w Prof. Dr. Barbara Plank, Annette Green and Claudia Schulze</li><li>8:00 pm <strong>Round Tables</strong> held by the mentors with topics:</li><li>8:30 pm Networking</li></ul><h3 id=speakers>Speakers</h3><p><img src=https://bplank.github.io/images/barbara.png alt="Prof. Barbara Plank ><"></p><p><a href=https://bplank.github.io/><strong>Prof. Dr. Barbara Plank</strong></a> is a full Professor (Chair) for AI and Computational Linguistics at LMU Munich.
She is the research lab lead of the Munich AI and Natural Language Processing lab (MaiNLP) and co-director of the Center for Information and Language Processing (CIS).
She is also professor (part-time) at ITU (IT University of Copenhagen), and co-lead of NLP North.</p><p><img src="https://media.licdn.com/dms/image/C4E03AQG3KI49IBsABw/profile-displayphoto-shrink_800_800/0/1656340952869?e=2147483647&amp;v=beta&amp;t=6QLCCgVL1R69U-8sLADFy4831RQ1d6WDTzvgQNaTiHc" alt="Annette Green ><"></p><p><a href=https://de.linkedin.com/in/annettegreen/><strong>Annette Green</strong></a> and her team at Microsoft are responsible for holistic relationships with key customers in Media & Entertainment as well as the Professional Services segment with companies in the consulting, software and construction industries.â€¯ Prior to joining Microsoft in 2022, she led the German, Austrian and Swiss operations of SAS, a leading provider of data analytics and artificial intelligence solutions, since January 2019.â€¯She holds a bachelor&rsquo;s degree in computer science from North Carolina State University.</p><p><img src=https://convalid-ai.de/static/team/claudia.png alt="Claudia Schulze ><"></p><p><a href=https://de.linkedin.com/in/claudia-schulze-43a36486><strong>Claudia Schulze</strong></a> is the managing director and co-founder of CONVALID Analytics, a Munich-based data analytics startup whose mission is to bring data science to business actions. Prior to that, she worked as a management consultant at SMP Strategy Consulting for about 8 years. She studied at the University of Maastricht (Netherlands) and the University of Queensland (Australia) and holds a Master of Science in International Business Economics.</p><h3 id=moderator>Moderator</h3><p><img src=https://sxu3.github.io/authors/admin/avatar_hu91610b169a7652533ea654a0d393ba5d_895245_270x270_fill_q75_lanczos_center.jpg alt="Shanshan Xu ><">
<a href=https://sxu3.github.io//><strong>Shanshan Xu</strong></a> Shanshan is a PhD student at LegalTech at TU Munich. Her research interest is NLP in Legal domain, Computational Social Science and Computational Linguistics. She is also an organizer of <a href=https://munich-nlp.github.io/>MunichðŸ¥¨NLP</a>. In this role, she strives to support and encourage women to work in NLP, and is committed to promoting diversity and inclusivity in the field.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>April 17, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/misalignment-of-legal-judgement/ rel=bookmark>The misalignment of legal judgement prediction model with expert and how to improve it</a></h1></header><div class=entry-content><p><img src=/images/ev_legal_nlp/theme_photo.png alt="The misalignment of legal judgement prediction model with expert and how to improve it ><"></p><h3 id=about-this-event>About this Event</h3><p>What does robot judege/ Legal Judgment Prediction (LJP) model actually predict from? I will talk about that neural LJP models without expert-informed adjustments can be vulnerable to shallow, distracting surface signals. Our experiments on neural LJP predicting European Court of Human Rights cases shows adversarial training can help better align models with experts, and in many cases can even achieve better prediction performance.</p><p><img src=https://sxu3.github.io/authors/admin/avatar_hu91610b169a7652533ea654a0d393ba5d_895245_270x270_fill_q75_lanczos_center.jpg alt="Shanshan Xu ><"></p><p><a href=https://sxu3.github.io/><strong>Shanshan Xu</strong></a> is a PhD student of Legal Tech in the Department of Informatics at the Technical University of Munich. Before transferring her PhD to TUM, she was a PhD student at L3S Research Center. Previous to that, she worked as a speech scientist at Nuance Communications/Cerence. She did her master in Cultural and Cognitive Linguistics at LMU Munich. Her research interest is NLP in LegalTech, Computational Social Science and Computational Linguistics.</p></div></article></div></div><center class><ul class=pagination><ul class="pagination pagination-default"><li class="page-item disabled"><a aria-disabled=true aria-label=First class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;&#171;</span></a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Previous class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;</span></a></li><li class="page-item active"><a aria-current=page aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/home/pastevents/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/home/pastevents/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/home/pastevents/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/home/pastevents/page/2/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/home/pastevents/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></ul></center></div></main><footer id=footer><div class=container><div class=row><div class="col-md-3 widget"><h3 class=widget-title>Follow us!</h3><div class=widget-body><p class=follow-me-icons><a href=https://discord.com/invite/BgFaZgZ38N target=_blank><i class="fab fa-discord fa-1x"></i></a>
<a href=https://www.youtube.com/channel/UCmpRQbcw7dOiXSyWpGYwk3Q target=_blank><i class="fab fa-youtube fa-1x"></i></a>
<a href=https://twitter.com/munichnlp target=_blank><i class="fab fa-twitter-square fa-1x"></i></a>
<a href=https://www.linkedin.com/company/munich-nlp/ target=_blank><i class="fab fa-linkedin fa-1x"></i></a>
<a href=https://github.com/Munich-NLP target=_blank><i class="fab fa-github fa-1x"></i></a>
<a href=mailto:munichnlp@gmail.com target=_blank><i class="fas fa-envelope-square fa-1x"></i></a></p></div></div></div></div></footer><script src=https://code.jquery.com/jquery-1.12.4.min.js></script>
<script src=https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js></script>
<script src=https://munich-nlp.github.io/js/bundle.min.8adc00f11fb328590a42ed3b14d3ec5b116abb98395a8a662d782f2150a7de6cc85eacb26c14724bb0c5130a11be2933c9b4f835cd3a053e90f036e210fbdd5d.js integrity="sha512-itwA8R+zKFkKQu07FNPsWxFqu5g5WopmLXgvIVCn3mzIXqyybBRyS7DFEwoRvikzybT4Nc06BT6Q8DbiEPvdXQ=="></script>
<script id=dsq-count-scr src=//hugo-initio-site.disqus.com/count.js async></script>
<script></script></body></html></body></html>