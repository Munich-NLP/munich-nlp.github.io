<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content="map[]"><title>Past Events</title><link rel="shortcut icon" href=https://munich-nlp.github.io/images/favicon.png><link href=https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css rel=stylesheet><script defer src=https://use.fontawesome.com/releases/v5.0.11/js/all.js integrity=sha384-ImVoB8Er8knetgQakxuBS4G3RSkyD8IZVVQCAnmRJrDwqJFYUE4YOv+DbIofcO9C crossorigin=anonymous></script>
<link rel=stylesheet href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700"><link rel=stylesheet href=https://munich-nlp.github.io/css/styles.min.ee9878fb7975c98855fa270ff7cfab08fc1644cf609d7aa8cb8338f5cba9dd1f2fafaf1e708aab938e9e61081d30e63175872b714e7a4dee0c40f128687f4075.css integrity="sha512-7ph4+3l1yYhV+icP98+rCPwWRM9gnXqoy4M49cup3R8vr68ecIqrk46eYQgdMOYxdYcrcU56Te4MQPEoaH9AdQ=="><style>@import 'https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@300&display=swap'</style></head><body class=home><header id=header><div id=head class=parallax data-parallax-speed=2 style=background-image:url(https://munich-nlp.github.io/)><h1 id=logo class=text-center><img class=img-noborder src=https://munich-nlp.github.io/images/munichnlp.png alt>
<span class=tagline><br><a href=mailto:></a></span></h1></div><nav class="navbar navbar-default"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#bs-example-navbar-collapse-1 aria-expanded=true>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="navbar-collapse collapse" id=bs-example-navbar-collapse-1><ul class="nav navbar-nav"><li><a href=/#about>About</a></li><li><a href=/#upcomingevents>Upcoming events</a></li><li><a href=/#pastevents>Past events</a></li><li><a href=/#partners>Partners</a></li><li><a href=/#organizers>Organizers</a></li></ul></div></div></nav></header><main id=main><div class=container><div class="row topspace"><div class="col-sm-8 col-sm-offset-2"><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>April 11, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/constrained-clustering/ rel=bookmark>CC-Top: Constrained Clustering for Dynamic Topic Discovery</a></h1></header><div class=entry-content><p><img src=/images/ev_cc/theme_photo.jpeg alt="CC-Top: Constrained Clustering for Dynamic Topic Discovery ><"></p><h3 id=about-this-event>About this Event</h3><p>Research on multi-class text classification of short texts mainly focuses on supervised (transfer) learning approaches, requiring a finite set of pre-defined classes which is constant over time. This talk covers deep constrained clustering (CC) as an alternative to supervised learning approaches in a setting with a dynamically changing number of classes, a task we introduce as dynamic topic discovery (DTD).
<a href=https://aclanthology.org/2022.evonlp-1.5/>(Link to the paper)</a></p><p><img src=https://www.slds.stat.uni-muenchen.de/images/janngoschenhofer.png alt="Jann Goschenhoffer ><"></p><p><a href=https://www.slds.stat.uni-muenchen.de/people/goschenhofer/><strong>Jann Goschenhofer</strong></a> is a final-year PhD student at the working group for the SLDS chair at LMU Munich in cooperation with the Fraunhofer ADA Lovelace Center. Currently, he focuses on Constrained Clustering and Positive Unlabeled Learning.</p><p><img src=/images/assenmacher.png alt="Dr. Matthias Aßenmacher ><"></p><p><a href=https://assenmacher-mat.github.io/><strong>Dr. Matthias Aßenmacher</strong></a> is a postdoctoral researcher at the Chair of SLDS chair and the NFDI Consortium for Business, Economic and Related Data (BERD@NFDI). In 2021, he finished his PhD focusing on Natural Language Processing. He works on a diverse set of NLP Applications, including Active Learning, Bias and multi-modal use cases.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>March 23, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/rel-repr-enable-zero-shot-lat-spc-com/ rel=bookmark>Relative representations enable zero-shot latent space communication</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/yj--paX6ZT4 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p><img src=https://luca.moschella.dev/authors/admin/avatar_hu9be67e9552adf247e4ea5a8f21f5da94_2673226_270x270_fill_q75_lanczos_center.jpg alt="Luca Moschella ><"></p><p><a href=https://luca.moschella.dev/><strong>Luca Moschella</strong></a> is a Ph.D. student at Sapienza University of Rome in the Gladia research group led by Professor Emanuele Rodolà, previously a research intern at NNAISENSE and currently at NVIDIA. His research focuses on geometric deep learning and representation learning, particularly in the interaction between different neural systems.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>March 16, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/bringing-your-insights-to-life-with-ipyvizzu-story/ rel=bookmark>Bringing Your Insights to Life with ipyvizzu-story</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/ssoxqustneQ style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p>Presenting and communicating the outcomes of your analysis has never been more engaging. Say goodbye to dull slides and hello to animated data storytelling.</p><p>In this talk, one of the creators of <a href=https://github.com/vizzuhq/ipyvizzu-story>ipyvizzu-story</a> will demonstrate how this new open-source presentation tool, integrated with Jupyter Notebook and similar platforms, makes use of a simple Python interface to bring your data to life through animated stories.</p><p>We will delve into the syntax, logic, and evolution of ipyvizzu-story and the underlying chart morphing engine. By the end of the session, you will have a clear understanding of when, why, and how to utilize this tool to its fullest potential.</p><h3 id=speakers>Speakers</h3><p><img src="https://media.licdn.com/dms/image/C4D03AQHBmXBx_Ng06Q/profile-displayphoto-shrink_200_200/0/1516527754681?e=1683763200&amp;v=beta&amp;t=jf_b242_0t0IJvGzbB5qa867ZAQheXgg1-GSWkhex0k" alt="Peter Vidos ><"></p><p><a href=https://www.linkedin.com/in/petervidos><strong>Peter Vidos</strong></a> Peter is the CEO & Co-Founder of <a href=https://vizzuhq.com/>Vizzu</a>.</p><p>His primary focus is understanding how Vizzu&rsquo;s innovative approach to data visualization can be put to good use. Listening to people complaining about their current hurdles with building charts and presenting them is his main obsession, next to figuring out how to help data professionals utilize the power of animation in dataviz.</p><p>Peter has been involved with digital product development for over 15 years. Earlier products/projects he worked on cover mobile app testing, online analytics, data visualization, decision support, e-learning, educational administration & social. Still, building a selfie teleport just for fun is what he likes to boast about when asked about previous experiences.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>March 13, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/colab-pretraining-and-recycling-finetuned-models/ rel=bookmark>Collaborative pretraining and recycling finetuned models</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/Aw509ml198M style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p>This talk will discuss our recent advancements in recycling finetuned models and collaborative pretraining. We would describe how to harness the data and computation invested in one or more models to collaboratively improve the pre-trained model they originated from, once or over and over again. The work will also touch on our initial understanding of how and why fusing several models by weight averaging works. All of these are small steps towards evolving pretrained models that we create together as a community, join us, check the best models and feel free to contact me and ask questions.</p><h3 id=speakers>Speakers</h3><p><img src=https://static.wixstatic.com/media/24c4d9_6c5d12636b024fbeab35ae1761838a51~mv2_d_3264_4896_s_4_2.jpg/v1/fill/w_383,h_511,al_c,q_80,usm_0.66_1.00_0.01,enc_auto/24c4d9_6c5d12636b024fbeab35ae1761838a51~mv2_d_3264_4896_s_4_2.jpg alt="Leshem Choshen ><"></p><p><a href=https://ktilana.wixsite.com/leshem-choshen><strong>Leshem Choshen</strong></a> Leshem Choshen currently leads the ColD-fusion challenge at IBM, aiming to collaboratively pretrain and propose to recycle finetuned models to do so. He received the postdoctoral Fulbright fellowship as well as IAAI and Blavatnik best Ph.D. awards. With broad NLP and ML interests, he also worked on Reinforcement Learning, Evaluation and Understanding of how neural networks learn. In parallel, he participated in Project Debater, creating a machine that could hold a formal debate, ending in a Nature cover and live debate.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>March 10, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/nvidia-recsys-meetup/ rel=bookmark>NVIDIA RecSys Meetup</a></h1></header><div class=entry-content><p><img src=/images/ev_nvidia_meetup/theme_photo.jpeg alt="NVIDIA RecSys Meetup ><"></p><h3 id=about-this-event>About this Event</h3><p>Join us on March 10th in Munich to learn more about:</p><p>10 Things we learned by hosting a Kaggle competition, with Philipp Normann, Senior Data Scientist at OTTO</p><p>It’s hard to deliver even a simple recommender! With Pavel Klemenkov, Chief Data Scientist (Data Platform) at NVIDIA</p><p>Summary of participating in five RecSys competitions, with Benedikt Schifferer, Deep Learning Engineer at NVIDIA</p><p>Using Multimodal NNs for eCommerce, with Dr. Christof Henkel, Deep Learner at NVIDIA</p><p>Hosted at NVIDIA’s office in Munich, Germany (Einsteinstrasse 172, 81677 München), join us from 3 PM CET to listen to experts, tour the data center, chat with peers, and eat some delicious pizza!</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>March 9, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/fine-tuning-transformers-for-your-nlp-problem/ rel=bookmark>Fine-Tuning Transformers for Your NLP Problem - A Journey Through Past Kaggle Competitions</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/CG9j0duQrX0 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p>We will talk about leveraging the power of pretrained transformer models by adjusting and fine-tuning to fit custom problems. We illustrate the flexibility by discussing diverse use cases that were part of recent kaggle competitions like question answering, sentiment segmentation, multilingual toxicity detection or ordering of the code cells in a jupyter notebook.</p><h3 id=speaker>Speaker</h3><p><img src=https://secure-content.meetupstatic.com/images/classic-events/510988854/100x100.webp alt="Dr. Christof Henkel ><"></p><p><a href=https://www.kaggle.com/christofhenkel><strong>Dr. Christof Henkel</strong></a> works as an applied deep learning researcher at NVIDIA. His main interests are novel deep learning architectures related to graphs, computer vision, text and audio. He holds a PhD from the Ludwig-Maximilians-University in Munich where he studied mathematics and specialized in stochastic processes. He is a triple kaggle grandmaster and after participating in more than 50 kaggle competitions he reached rank #1 in the world-wide competition ranking in 2022.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>March 6, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/modern-labeling-techniques/ rel=bookmark>How to leverage modern labeling techniques to overcome the cold start problem</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/2NJOmvuWlnw style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src=/images/ev_modern_labeling/theme_photo.png alt='How to leverage modern labeling techniques to overcome the cold start problem"><'></p><h3 id=about-this-event>About this Event</h3><p>Whether you are a large corporation or a single person, getting started with machine learning is not easy, especially if you have little to no data. To overcome this cold-start problem, we would like to show you how to leverage state-of-the-art techniques to kickstart your next NLP project and get high-quality labels fast. We&rsquo;ll cover topics such as active learning, weak supervision as well as confident and zero-shot learning. Your hosts will be Moritz, Div, and Leo from the company Kern AI, who use these advanced techniques in their open-source data-centric IDE for NLP called “refinery”.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>February 27, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/linguistic-perspective/ rel=bookmark>The past, present, and future of NLP from a linguistic perspective</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/tBQKswYlQNs style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p>Since the first modern Neural Networks were designed in the 1980s, NLP and the Linguistic debate about the modelling of human language have mostly diverged. Nevertheless, they have interacted and shaped each other in important ways, e.g. in the discussion about whether SotA language models reach their performances the &lsquo;right‘ way. This talk will explore the development of NLP from the perspective of the Linguistic debate of rule-l vs. usage-based theories, and highlight why taking a stand in this debate is important for finding solutions to the challenges facing SotA LLMs.</p><h3 id=speakers>Speakers</h3><p><img src=https://www.cis.uni-muenchen.de/~weissweiler/util/images/profile.jpg alt="Leonie Weissweiler ><"></p><p><a href=https://www.cis.uni-muenchen.de/~weissweiler/><strong>Leonie Weissweiler</strong></a> is a PhD student at CIS LMU, supervised by Prof. Schütze. She is interested in leveraging methods from NLP to contribute to the empirical study of the emergent structure of Language, its evolution and processing in the brain. Her current research focuses on multilingual unsupervised Morphosyntax and probing language models for Construction Grammar together with Carnegie Mellon University.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>February 21, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/qa-langchain-qdrant/ rel=bookmark>Question Answering with LangChain and Qdrant without boilerplate</a></h1></header><div class=entry-content><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/D7BJVN92vPE style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=about-this-event>About this Event</h3><p>Hands-on introduction to designing a Question Answering system that combines Large Language Models and vector search. We&rsquo;ll go through a complete development of such a tool using Langchain and Qdrant as a knowledge base.</p><h3 id=speakers>Speakers</h3><p><img src="https://media.licdn.com/dms/image/C4D03AQFJw2RLNROWZA/profile-displayphoto-shrink_200_200/0/1551536249197?e=1680739200&amp;v=beta&amp;t=tm8JPsO8rjE6P7EZjcK4cXa7G1BdfNeLwa_qu1KMl4U" alt="Kacper Łukawsk ><"></p><p><a href=https://www.linkedin.com/in/kacperlukawski/><strong>Kacper Łukawsk</strong></a> is a Developer Advocate at Qdrant - an open-source neural search engine. His experience is mostly related to data engineering, machine learning, and software design. Recently he’s been exploring the world of similarity learning and vector search.</p></div></article><article class=post><header class=entry-header><div class=entry-meta><span class=posted-on><time class="entry-date published" datetime>February 16, 2023</time></span></div><h1 class=entry-title><a href=https://munich-nlp.github.io/events/pydata-munichnlp-vol3/ rel=bookmark>PyData x MunichNLP Vol. 3 - ML Models in Production</a></h1></header><div class=entry-content><p><img src=/images/ev_nlp_pydata_v3/theme_photo.png alt="PyData x MunichNLP Vol. 3 - ML Models in Production><"></p><h3 id=about-this-event>About this Event</h3><p>Many companies are already using machine learning and artificial intelligence algorithms. However, the decisive factors are not only to train the best fitting model but the time to value of the models is crucial. To improve the time to value consistently, an end-to-end MLOps process that is required to train, test, deploy, run, and monitor ML models is essential for a company&rsquo;s success. This pipeline also should consider governance and security aspects. Building such a MLOps pipeline is a complex journey as the process consists of integration and choosing many different tools of a machine learning live cycle. It also requires the expertise of a combination of different stakeholder such as DevOps, Data Engineering and Data Science. This talk gives an insight of lessons learned by industry projects to efficiently setting up a complete ML and AI end-to-end pipeline to provide and maintain fast and accurate predictions.</p><h3 id=speakers>Speakers</h3><p><img src="https://media.licdn.com/dms/image/C5603AQEmpLOC9xf8nA/profile-displayphoto-shrink_800_800/0/1516895838564?e=2147483647&amp;v=beta&amp;t=QnqHWOSaMxwbjJFLaKnTlxy9g7aOUENZufiPkLyZbFk" alt="Eric Joachim Liese ><"></p><p><a href=https://de.linkedin.com/in/achimliese><strong>Eric Joachim Liese</strong></a>, who holds a degree in Mathematics and Computer Science with a focus on Machine Learning and AI, has worked as a Senior Data Scientist, ML Engineer, and Consultant for several years. He has experience designing concepts for automating the development of AI products through the creation of end-to-end MLOps pipelines and strategies for companies to become data and AI-driven. Prior to this, he worked as a software engineer for over a decade and later as a lead developer on several projects. Currently, Eric is a Lead Architect and Advisor for AI and Big Data infrastructure, helping BSH develop a strategy to become a data and AI-driven company. His responsibilities include designing Data Lakes for BSH, with a focus on concepts for automating data ingestion, ETL, data quality, and productionization of ML/AI processes on AWS.</p><p><img src="https://media.licdn.com/dms/image/D4E03AQECRTG7XmHfPg/profile-displayphoto-shrink_800_800/0/1672841740519?e=2147483647&amp;v=beta&amp;t=pewuW-wBk-ks1Utq6ehUgXjDm3c9p-ORdPNhMAYyK0Y" alt="Prof. Dr. René Brunner ><"></p><p><a href=https://www.macromedia-fachhochschule.de/de/menschen/rene-brunner/><strong>Prof. Dr. René Brunner</strong></a> has been a lecturer for Data Science and programming for many years. Over 35,000 participants have already attended his online courses, workshops and seminars on the Udemy platform. Topics include Artificial Intelligence, Machine Learning, Dev Ops, Automations, Python, R, Image Recognition, Speech Analytics, Deep Learning, Docker and Tableau.</p></div></article></div></div><center class><ul class=pagination><ul class="pagination pagination-default"><li class=page-item><a href=/home/pastevents/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/home/pastevents/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/home/pastevents/ aria-label="Page 1" class=page-link role=button>1</a></li><li class="page-item active"><a aria-current=page aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/home/pastevents/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/home/pastevents/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/home/pastevents/page/3/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/home/pastevents/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></ul></center></div></main><footer id=footer><div class=container><div class=row><div class="col-md-3 widget"><h3 class=widget-title>Follow us!</h3><div class=widget-body><p class=follow-me-icons><a href=https://discord.com/invite/BgFaZgZ38N target=_blank><i class="fab fa-discord fa-1x"></i></a>
<a href=https://www.youtube.com/channel/UCmpRQbcw7dOiXSyWpGYwk3Q target=_blank><i class="fab fa-youtube fa-1x"></i></a>
<a href=https://twitter.com/munichnlp target=_blank><i class="fab fa-twitter-square fa-1x"></i></a>
<a href=https://www.linkedin.com/company/munich-nlp/ target=_blank><i class="fab fa-linkedin fa-1x"></i></a>
<a href=https://github.com/Munich-NLP target=_blank><i class="fab fa-github fa-1x"></i></a>
<a href=mailto:munichnlp@gmail.com target=_blank><i class="fas fa-envelope-square fa-1x"></i></a></p></div></div></div></div></footer><script src=https://code.jquery.com/jquery-1.12.4.min.js></script>
<script src=https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js></script>
<script src=https://munich-nlp.github.io/js/bundle.min.8adc00f11fb328590a42ed3b14d3ec5b116abb98395a8a662d782f2150a7de6cc85eacb26c14724bb0c5130a11be2933c9b4f835cd3a053e90f036e210fbdd5d.js integrity="sha512-itwA8R+zKFkKQu07FNPsWxFqu5g5WopmLXgvIVCn3mzIXqyybBRyS7DFEwoRvikzybT4Nc06BT6Q8DbiEPvdXQ=="></script>
<script id=dsq-count-scr src=//hugo-initio-site.disqus.com/count.js async></script>
<script></script></body></html></body></html>